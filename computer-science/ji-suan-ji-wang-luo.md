---
description: 先根据小林coding进行总结，后面再逐渐添加面经
---

# 计算机网络

## **1.键入网址到网页显示，期间发生了什么** <a href="#22-jian-ru-wang-zhi-dao-wang-ye-xian-shi-qi-jian-fa-sheng-le-shen-me" id="22-jian-ru-wang-zhi-dao-wang-ye-xian-shi-qi-jian-fa-sheng-le-shen-me"></a>

浏览器做的第一步工作是解析 URL ,URL由协议，域名，目录和文件名组成

> 当没有路径名时，就代表访问根目录下事先设置的**默认文件**，也就是 `/index.html` 或者 `/default.html` 这些文件，这样就不会发生混乱了

对 `URL` 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息

接着需要通过DNS对域名进行解析，得到web服务器的ip地址（本地会有DNS缓存，这也是DNS具有健壮性的重要原因之一）

HTTP 报文是基于 TCP 传输的 , 接着需要通过3次握手建立TCP链接，如果数据超过了MSS的大小还需要进行拆分，最终组成TCP报文段，交由网络层处理

网络层会加上IP头部，随后查表寻找下一跳，如果找到了就直接加上MAC头部，如果没找到就发ARP协议广播寻找，如果找到了会将其缓存到表内

最后通过交换机，路由器送达服务器

数据包抵达服务器后，服务器会查看MAC 头部， IP 头部， TCP 头部，以及序列号

&#x20;HTTP 进程把这个网页封装在 HTTP 响应报文里返回 （ 相同步骤）

浏览器去渲染页面

断开连接



## 2. HTTP是什么

HTTP 超文本传输协议，是一个在计算机世界里专门用来在**两点之间传输数据**的约定和规范



## 3.HTTP 常见的状态码有哪些？

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求

* 「**200 OK**」常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
* 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
* 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

* 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
* 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

* 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。(条件GET)

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

* 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
* 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
* 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

* 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
* 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
* 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
* 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。



## 3.GET 和 POST 有什么区别？&#x20;

**GET 的语义是从服务器获取指定的资源**

**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**



## 4. HTTP 缓存有哪些实现方式？

* 强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。 强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：
* `Cache-Control`， 是一个相对时间；
* `Expires`，是一个绝对时间；



* **协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**

协商缓存可以基于两种头部来实现。

* 请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现
* 请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段

第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。

注意，**协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。



## 5.HTTP/1.1 的优点有哪些？ <a href="#http11-de-you-dian-you-na-xie" id="http11-de-you-dian-you-na-xie"></a>

* _简单_   HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**
* _灵活和易于扩展_    HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**
* _应用广泛和跨平台_&#x20;



## 6. HTTP/1.1 的缺点有哪些？

* _无状态_   因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务  ,但是服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦 （如一些需要确认用户身份的接口），可以使用cookie解决
* _明文传输_  方便阅读，为我们调试工作带了极大的便利性，但信息的内容都毫无隐私可言，很容易就能被窃取
* 不安全 通信使用明文，
  * 不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多**
  * 无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告**



## 7. HTTP 与 HTTPS 有哪些区别？

* HTTP 是明文传输，存在安全风险的问题。HTTPS 在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
* HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
* 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
* HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



## 8.HTTPS 解决了 HTTP 的哪些问题？

* **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
* **篡改风险**，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。
* **冒充风险**，比如冒充淘宝网站，用户钱容易没。

如何解决？

* **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
* **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
* 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

## 9. HTTPS 的应用数据是如何保证完整性的？

TLS 在实现上分为**握手协议**和**记录协议**两层：

* TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；
* TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；



## 10.HTTPS 一定安全可靠吗？

**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全**



## 11.HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

* 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
* 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

不足 ：

* 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大
* 发送冗长的首部，相互发送相同首部浪费较多
* 队头阻塞
* 没有请求优先级控制
* 请求只能从客户端开始，服务器被动响应



## 12. HTTP/2 做了什么优化？

HTTP/2 相比 HTTP/1.1 性能上的改进：

* 头部压缩（`HPACK` 算法）
* 二进制格式（头信息帧和数据帧） &#x20;
* 并发传输（多个 Stream 复用在一条 TCP 连接）
* 服务器主动推送资源（**双方都可以建立 Stream**， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号）



## 13.HTTP/2 有什么缺陷？

在TCP层仍有队头阻塞问题

> **TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题**



## 14.HTTP/3 做了哪些优化？

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**

UDP 发送是不管顺序，也不管丢包，所以不会出现像 HTTP/2 队头阻塞的问题

&#x20;UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的**可靠性传输**。

QUIC 有以下 3 个特点。

* 无队头阻塞（**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响**）
* 更快的连接建立（QUIC 协议握手过程只需要 1 RTT)
* 连接迁移(通过**连接 ID** 来标记通信的两个端点，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接)



## 15.RPC

* 纯裸 TCP 是能收发数据，但它是个**无边界**的数据流，上层需要定义**消息格式**用于定义**消息边界**。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议。
* **RPC 本质上不算是协议，而是一种调用方式**，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，**不一定非得基于 TCP 协议**。
* 从发展历史来说，**HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合**。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。
* RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 **性能**要更好，所以大部分公司内部都还在使用 RPC。
* **HTTP/2.0** 在 **HTTP/1.1** 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。

## 16.websocket

* TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
* 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。
* 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。
* WebSocket 和 socket 几乎没有任何关系，只是叫法相似。
* 正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。



## 17.UDP 和 TCP 有什么区别



## 18.TCP 和 UDP 可以使用同一个端口吗？

可以的。

TCP 和 UDP 传输协议，在内核中是两个完全独立的软件模块

因此， TCP/UDP 各自的端口号也相互独立，互不影响。



## 19. 多个 TCP 服务进程可以绑定同一个端口吗？

**如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”**

> 如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错。
>
> 这是因为 0.0.0.0 地址比较特殊，代表任意地址，意味着绑定了 0.0.0.0 地址，相当于把主机上的所有 IP 地址都绑定了。



## 20.TCP 三次握手过程是怎样的？

* 客户端发起请求，会随机初始化一个序列号client\_isn ,把SYN标志位标志为一，表示SYN报文，随后发送
* 服务端应答报文也会令SYN = 1，ACK= 1  ，确认应答号=  client\_isn + 1 ，随机初始化自己的序号`server_isn`
* 客户端回复最后一个应答报文，令ACK= 1,确认应答号server\_isn + 1

**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**



## 21.为什么是三次握手？不是两次、四次？

* 三次握手才可以阻止重复历史连接的初始化（主要原因）
* 三次握手才可以同步双方的初始序列号
* 三次握手才可以避免资源浪费



## 22.为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

* 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；
* 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；



## 23.既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文，就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发整个 TCP 报文，所以由 IP 层进行分片传输，是非常没有效率的

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率



## 24.第一次握手丢失了，会发生什么？

会触发超时重传机制，超时时间由操作系统决定，重传的次数可以自己定义



## 25.第二次握手丢失了，会发生什么？

当第二次握手丢失了，客户端和服务端都会重传

* 客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 `tcp_syn_retries`内核参数决定；
* 服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 `tcp_synack_retries` 内核参数决定。



## 26.第三次握手丢失了，会发生什么？

如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数



## 27.什么是 SYN 攻击？如何避免 SYN 攻击？

攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务

避免 SYN 攻击方式，可以有以下四种方法：

* 调大 netdev\_max\_backlog；
* 增大 TCP 半连接队列；
* 开启 tcp\_syncookies；
* 减少 SYN+ACK 重传次数



## 28.TCP 四次挥手过程是怎样的？

* 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
* 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
* 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
* 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
* 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
* 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
* 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME\_WAIT 状态。**



## 29.为什么挥手需要四次？

* 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
* 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

但是**在特定情况下，四次挥手是可以变成三次挥手的**



## 30. 挥手丢失

### 第一次挥手丢失

* 当客户端超时重传 3 次 FIN 报文后，由于 tcp\_orphan\_retries 为 3，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK报文），那么客户端就会断开连接。



### 第二次挥手丢失

ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数



### 第三次挥手丢失

* 当服务端重传第三次挥手报文的次数达到了 3 次后，由于 tcp\_orphan\_retries 为 3，达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。
* 客户端因为是通过 close 函数关闭连接的，处于 FIN\_WAIT\_2 状态是有时长限制的，如果 tcp\_fin\_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。



### 第四次挥手丢失

* 当服务端重传第三次挥手报文达到 2 时，由于 tcp\_orphan\_retries 为 2， 达到了最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。
* 客户端在收到第三次挥手后，就会进入 TIME\_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。



## 31.为什么 TIME\_WAIT 等待的时间是 2MSL？

TIME\_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

**2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME\_WAIT 状态的连接可以应对。

为什么不考虑更长的时长 - - - 连续两次丢包的概率实在是太小了，忽略它比解决它更具性价比



## 32.为什么需要 TIME\_WAIT 状态？

* 防止历史连接中的数据，被后面相同四元组的连接错误的接收；

> **序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据**

* 保证「被动关闭连接」的一方，能被正确的关闭；



## 33.TIME\_WAIT 过多有什么危害？

* 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
* 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围。



## 34.如何优化 TIME\_WAIT？

* 打开 net.ipv4.tcp\_tw\_reuse 和 net.ipv4.tcp\_timestamps 选项；
* net.ipv4.tcp\_max\_tw\_buckets
* 程序中使用 SO\_LINGER ，应用强制使用 RST 关闭。



## 35.服务器出现大量 TIME\_WAIT 状态的原因有哪些？

TIME\_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME\_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接

* 第一个场景：HTTP 没有使用长连接
* 第二个场景：HTTP 长连接超时
* 第三个场景：HTTP 长连接的请求数量达到上限



## 36.服务器出现大量 CLOSE\_WAIT 状态的原因有哪些？

**当服务端出现大量 CLOSE\_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close**



## 37.如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP 保活

如果开启了 TCP 保活，需要考虑以下几种情况：

* 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
* 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
* 第三种，是对端主机宕机（_注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机_），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。



## 38.如果已经建立了连接，但是服务端的进程崩溃会发生什么？

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。



## 39.重传机制

所以 TCP 针对数据包丢失的情况，会用**重传机制**解决。

接下来说说常见的重传机制：

* 超时重传
* 快速重传
* SACK
* D-SACK

### 超时重传 <a href="#chao-shi-zhong-chuan" id="chao-shi-zhong-chuan"></a>

TCP 会在以下两种情况发生超时重传：

* 数据包丢失
* 确认应答丢失

当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；

当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。



### 快速重传 <a href="#kuai-su-zhong-chuan" id="kuai-su-zhong-chuan"></a>

快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制只解决了超时时间的问题，但是还存在**重传的时候，是重传一个，还是重传所有的问题。**



### SACK 方法 <a href="#sack-fang-fa" id="sack-fang-fa"></a>

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。



### Duplicate SACK <a href="#duplicate-sack" id="duplicate-sack"></a>

其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了**

`D-SACK` 有这么几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;



## 40.滑动窗口

窗口大小由哪一方决定？

TCP 头里有一个字段叫 `Window`，也就是窗口大小，通常窗口的大小是由接收方的窗口大小来决定的

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来**

接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。



## 41.流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制**



### 操作系统缓冲区与滑动窗口的关系

如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。**为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。**



### 窗口关闭 <a href="#chuang-kou-guan-bi" id="chuang-kou-guan-bi"></a>

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭**

TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

* 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
* 如果接收窗口不是 0，那么死锁的局面就可以被打破了。



### 糊涂窗口综合症 <a href="#hu-tu-chuang-kou-zong-he-zheng" id="hu-tu-chuang-kou-zong-he-zheng"></a>

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

要解决糊涂窗口综合症，同时解决这两个问题：

* 让接收方不通告小窗口给发送方

当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。反之，则打开

* 让发送方避免发送小数据

使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据：

* 条件一：要等到窗口大小 >= `MSS` 并且 数据大小 >= `MSS`；
* 条件二：收到之前发送数据的 `ack` 回包；

只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。**接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**





## 42.拥塞控制 <a href="#yong-sai-kong-zhi" id="yong-sai-kong-zhi"></a>

**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络**

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口 `cwnd` 变化的规则：

* 只要网络中没有出现拥塞，`cwnd` 就会增大；
* 但网络中出现了拥塞，`cwnd` 就减少；

### 怎么知道当前网络是否出现了拥塞

其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

### 拥塞控制算法

#### 慢启动 <a href="#man-qi-dong" id="man-qi-dong"></a>

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量

慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

* 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
* 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。\


#### 拥塞避免算法

当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法

拥塞避免算法它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**

#### &#x20;拥塞发生 <a href="#yong-sai-fa-sheng" id="yong-sai-fa-sheng"></a>

发生超时重传的拥塞发生算法

这个时候，ssthresh 和 cwnd 的值会发生变化：

* `ssthresh` 设为 `cwnd/2`，
* `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）



发生快速重传的拥塞发生算法

`ssthresh` 和 `cwnd` 变化如下：

* `cwnd = cwnd/2` ，也就是设置为原来的一半;
* `ssthresh = cwnd`;
* 进入快速恢复算法



#### 快速恢复算法

进入快速恢复算法如下：

* 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
* 重传丢失的数据包；
* 如果再收到重复的 ACK，那么 cwnd 增加 1；
* 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；







